{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55c3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import statistics as stats\n",
    "import scipy\n",
    "import string as st\n",
    "import lmfit\n",
    "from lmfit import Model\n",
    "from lmfit import models\n",
    "from lmfit.models import *\n",
    "from scipy import io\n",
    "from scipy.fftpack import dct, idct\n",
    "from itertools import combinations\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import inspect\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e987dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker1 ={'var1':[10,11,12,10,12], 'var2':[14,15,13,12,15]}\n",
    "\n",
    "speaker2 = {'var1':[20,17,15,16], 'var2':[18,19,17,19]}\n",
    "\n",
    "background = {'speak1' :\n",
    "                  {'var1':[10,11,12,10,13],\n",
    "                   'var2':[14,15,13,18,15]},\n",
    "             'speak2' :\n",
    "                  {'var1':[19, 18, 17, 20, 17, 18],\n",
    "                   'var2':[16, 19, 17, 18, 19, 17]},\n",
    "             'speak3' :\n",
    "                  {'var1':[13, 12, 15],\n",
    "                   'var2':[14, 15, 17]},\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c415c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_ratio(background, file1, file2):\n",
    "    \n",
    "    off_covar = None\n",
    "\n",
    "    ######################################################\n",
    "    ### some prior calculations on the background data ###\n",
    "    ######################################################\n",
    "\n",
    "    # Get the number of speakers\n",
    "    num_speakers = len(background)\n",
    "\n",
    "    # get the number of variables\n",
    "    num_variables = len(next(iter(background.values())))\n",
    "\n",
    "    # get the number of measurements \n",
    "    num_measur = 0\n",
    "    for speaker in background.values():\n",
    "        first_variable = next(iter(speaker.values()))\n",
    "        num_measur += len(first_variable)\n",
    "\n",
    "    # background mean : overall mean for each variable. \n",
    "\n",
    "    var_all = {}\n",
    "\n",
    "    #first reshape the data to put all values together, regardless of speaker\n",
    "    for speaker, variables in background.items(): \n",
    "        # loop through every variable \n",
    "        for variable, values in variables.items():\n",
    "            # if the new variable has not yet been added to the new dictionary, add it.\n",
    "            var_all.setdefault(variable, [])\n",
    "\n",
    "            # add the values to the coefficient list\n",
    "            var_all[variable].extend(values)\n",
    "\n",
    "    #calculate the mean of each variable in the background data:\n",
    "\n",
    "    background_means = {}\n",
    "\n",
    "    for variable, values in var_all.items():\n",
    "        background_means.setdefault(variable, )\n",
    "        background_means[variable] = np.mean(values)\n",
    "\n",
    "    #mean of each variable for eah of the speakers in the background data: \n",
    "\n",
    "    var_means_per_speaker = {}\n",
    "\n",
    "    for speaker,var in background.items():\n",
    "        var_means_per_speaker[speaker] = []\n",
    "        for variable, values in background[speaker].items():\n",
    "            var_means_per_speaker[speaker].append(np.mean(values))\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    ### within group covariance matrix ###\n",
    "    ######################################\n",
    "\n",
    "    #calculated differently to make use of the cov function from the numpy package. \n",
    "\n",
    "    #create a covariance matrix for each speaker. \n",
    "                        \n",
    "    cov_matrices = {}\n",
    "    for speaker, values in background.items():\n",
    "        speaker_data = np.vstack(list(values.values()))\n",
    "\n",
    "        numeric_data = speaker_data.astype(np.number)\n",
    "        cov_matrices[speaker] = np.cov(numeric_data)\n",
    "\n",
    "    #adding all matrices\n",
    "\n",
    "    matrices = [np.array(matrix) for matrix in cov_matrices.values()]\n",
    "    sum_matrices = sum(matrix[:matrix.shape[0], :matrix.shape[1]] for matrix in matrices)\n",
    "\n",
    "    # divide by the number of speakers.\n",
    "    within_group = sum_matrices/num_speakers\n",
    "\n",
    "    #######################################\n",
    "    ### between group covariance matrix ###\n",
    "    #######################################\n",
    "\n",
    "    #according to the changes introduced by Morrison to accomodate for unequal n across speakers. \n",
    "\n",
    "    #calculate the first part of the group covariance matrix equation.\n",
    "    Sstar= np.cov(np.array(list(var_means_per_speaker.values())), rowvar=False)\n",
    "\n",
    "    #final calculations\n",
    "    between_group_cov = Sstar - (sum_matrices/num_measur)\n",
    "\n",
    "    #between group inverse covariance\n",
    "    betw_inv = np.linalg.inv(between_group_cov)\n",
    "\n",
    "    #between group square root\n",
    "    betw_sqrt = scipy.linalg.sqrtm(between_group_cov)\n",
    "\n",
    "    ####################################\n",
    "    ### calulations on offender data ###\n",
    "    ####################################\n",
    "\n",
    "    # number of measures\n",
    "    off_num_measures = len(next(iter(file1.values())))\n",
    "\n",
    "    # offender mean\n",
    "    off_mean = []\n",
    "    for variable, values in file1.items():\n",
    "        off_mean.append(stats.mean(file1[variable])) \n",
    "\n",
    "    #offender covariance matrix \n",
    "\n",
    "    off_covar= [[value / off_num_measures for value in row] for row in within_group]\n",
    "        \n",
    "    #offender inverse covariance matrix.\n",
    "    off_inv = np.linalg.inv(off_covar)\n",
    "\n",
    "    #offender square root \n",
    "    off_sqrt = scipy.linalg.sqrtm(off_covar)\n",
    "\n",
    "    # offender square root inverse\n",
    "    off_sqrt_inv = np.linalg.inv(off_sqrt)\n",
    "\n",
    "     #################################\n",
    "     ### suspect data calculations ###\n",
    "    #################################\n",
    "\n",
    "    # number of measures\n",
    "    suspect_num_measures = len(next(iter(file2.values())))\n",
    "\n",
    "    # suspect mean\n",
    "    suspect_mean = []\n",
    "    for variable, values in file2.items():\n",
    "        suspect_mean.append(stats.mean(file2[variable])) \n",
    "\n",
    "    #suspect covariance matrix \n",
    "\n",
    "    suspect_covar = [[value / suspect_num_measures for value in row] for row in within_group]\n",
    "    suspect_covar = np.array(suspect_covar)\n",
    "\n",
    "    #suspect inverse covariance matrix.\n",
    "    suspect_inv = np.linalg.inv(suspect_covar)\n",
    "\n",
    "    #suspect square root \n",
    "    suspect_sqrt = scipy.linalg.sqrtm(suspect_covar)\n",
    "\n",
    "    # suspect square root inverse\n",
    "    suspect_sqrt_inv = np.linalg.inv(suspect_sqrt)\n",
    "\n",
    "    ###########################\n",
    "    ### smoothing parameter ###\n",
    "    ###########################\n",
    "    \n",
    "    # as given by Silverman(1986)\n",
    "\n",
    "    smooth_param= ((4/(2*num_variables+1))**(1/(num_variables+4)) \n",
    "                   * num_speakers**-(1/(num_variables+4)))\n",
    "\n",
    "    ####################################\n",
    "    ### a few other pre-calculations ###\n",
    "    ####################################\n",
    "\n",
    "    kernel = smooth_param**2 * between_group_cov\n",
    "\n",
    "    inv_kernel = np.linalg.inv(kernel)\n",
    "\n",
    "    kernel_typ = 0\n",
    "    dist_back_off = 0\n",
    "    dist_back_suspect = 0 \n",
    "    suspect_off_mean_typ = 0\n",
    "\n",
    "    suspect_off_mean_diff = np.subtract(suspect_mean, off_mean)\n",
    "    suspect_off_mean_typ = np.linalg.solve(off_inv \n",
    "                                           + suspect_inv, np.linalg.solve(off_covar, off_mean) \n",
    "                                           + np.linalg.solve(suspect_covar, suspect_mean))\n",
    "    \n",
    "    for speaker, values in var_means_per_speaker.items():\n",
    "        typicality = np.subtract(suspect_off_mean_typ, values)\n",
    "\n",
    "        #kernel density at typicality.\n",
    "        kernel_typ += (np.exp(-0.5 * typicality.T \n",
    "                             @ np.linalg.inv(np.linalg.inv(off_inv + suspect_inv) + kernel) \n",
    "                             @ typicality))\n",
    "\n",
    "    #calculations of the distance between background and offender data\n",
    "    dist_back_off += (np.exp(-0.5 * np.subtract(off_mean, values).T \n",
    "                                 @ np.linalg.inv(off_covar + kernel) \n",
    "                                 @ np.subtract(off_mean, values)))\n",
    "\n",
    "    #calculations of the distance between background and suspect data\n",
    "    dist_back_suspect += (np.exp(-0.5 * np.subtract(off_mean, values).T\n",
    "                                 @ np.linalg.inv(off_covar + kernel) \n",
    "                                 @ np.subtract(off_mean, values)))\n",
    "\n",
    "    #################\n",
    "    ### numerator ###\n",
    "    #################\n",
    "\n",
    "    numerator = ((2 * np.pi) **(-num_variables) \n",
    "                     * np.linalg.det(off_sqrt_inv) \n",
    "                     * np.linalg.det(suspect_sqrt_inv)\n",
    "                     * 1/np.sqrt(np.abs(np.linalg.det(between_group_cov))) \n",
    "                     * (num_speakers * smooth_param ** num_variables) ** (-1) \n",
    "                     * np.abs(np.linalg.det(off_inv + suspect_inv + inv_kernel)) ** (-0.5) \n",
    "                     * np.exp(-0.5 * \n",
    "                              suspect_off_mean_diff.T \n",
    "                              @ np.linalg.inv(suspect_covar + off_covar) \n",
    "                              @ suspect_off_mean_diff) \n",
    "                     * kernel_typ)\n",
    "\n",
    "    ###################\n",
    "    ### denominator ###\n",
    "    ###################\n",
    "\n",
    "    denominator = ( (2*np.pi)**-num_variables * 1/abs(np.linalg.det(between_group_cov))\n",
    "                       * (num_speakers * smooth_param**num_variables)**-2 \n",
    "\n",
    "                       * abs(np.linalg.det(suspect_sqrt_inv))\n",
    "                       * abs(np.linalg.det(suspect_inv + inv_kernel))**-0.5\n",
    "                       * dist_back_suspect\n",
    "\n",
    "                       * abs(np.linalg.det(off_sqrt_inv))\n",
    "                       * abs(np.linalg.det(off_inv + inv_kernel))**-0.5\n",
    "                       * dist_back_off)\n",
    "\n",
    "    ########################\n",
    "    ### likelihood ratio ###\n",
    "    ########################\n",
    "\n",
    "    likelihood_ratio= numerator / denominator\n",
    "\n",
    "    return(likelihood_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55d40c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.652194667121164e-10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_ratio(background, speaker1, speaker2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
